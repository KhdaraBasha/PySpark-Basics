{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1343bd34-feac-4f4c-95be-513e276a1464",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## WithColumn() and WithColumnRenamed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a54c47eb-b392-4d4c-a8db-2ea29d7b915d",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Read data from CSV file"
    }
   },
   "outputs": [],
   "source": [
    "# Path to data file\n",
    "path = '/Volumes/workspace/practice_db/sample_data/emp_1.csv'\n",
    "# Read data into Spark DataFrame\n",
    "emp_df = spark.read.csv(path, header=True)\n",
    "# Display sample data from the dataframe\n",
    "emp_df.show(2)\n",
    "# Display schema of the dataframe\n",
    "emp_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "39afd5f1-0e08-4c7d-9ff9-a0ef6bc3d4a0",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Add a new column based on existing column"
    }
   },
   "outputs": [],
   "source": [
    "emp_df.withColumn(\"salary1\", emp_df.salary*10).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "301256ee-1e7b-45e3-8043-9a20875f7bae",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Add a new column based on constant value"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "\n",
    "emp_df.withColumn('country', lit('India')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "52201612-55a6-41c7-9195-2eda90123c64",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Add a new column with a constant value zero (0)"
    }
   },
   "outputs": [],
   "source": [
    "emp_df.withColumn('increment', lit(0)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3a614e33-c4b6-4b3f-a597-9e9260294160",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Update existing schema"
    }
   },
   "outputs": [],
   "source": [
    "emp_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c6ba89f-6894-4858-a87b-da22689b9e81",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "emp_df.withColumn(\"salary\", col(\"salary\").cast(\"int\"))\\\n",
    "    .withColumn(\"emp_id\", col(\"emp_id\").cast(\"int\")).printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1ff6cdba-c508-46e0-b4d5-b08432cd00e9",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Rename Existing column"
    }
   },
   "outputs": [],
   "source": [
    "emp_df.withColumnRenamed('loc','location')\\\n",
    "    .withColumnRenamed('email', 'email_id')\\\n",
    "    .show(2)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "11-withcolumn-withcolumnrenamed-in-pysaprk",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
